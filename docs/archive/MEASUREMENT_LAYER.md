# Evidence-Based Measurement Layer

This document describes the architectural layer responsible for transforming raw employee interactions (choice, text) into psychometrically valid parameter signals.

## Architecture

```mermaid
graph TD
    User[User Input] -->|Raw Text| NL[Normalization Layer]
    NL -->|Option Code?| DC[Deterministic Coding]
    NL -->|Free Text?| LC[LLM Coding]
    DC -->|Evidence[]| MM[Parameter Mapper]
    LC -->|Evidence[]| MM
    MM -->|Signals (0..1)| Core[Frozen Core / Inference]
```

## Key Concepts

### 1. ItemSpec & Option Codes
Every question generated by the system includes an `ItemSpec`. For `choice` questions, each option carries a pre-determined `coding` (Evidence).
- **Benefit**: If a user selects "High Clarity", we don't need to guess. The option already maps to: `{ construct: 'role_clarity', direction: 1, strength: 0.9 }`.
- **Storage**: Serialized in `interactions.prompt_text` metadata.

### 2. Evidence Atomic Record
Instead of outputting abstract parameters directly, the interpretation layer outputs `Evidence`:
- **Construct**: Valid psychological construct (e.g., `psychological_safety`).
- **Direction**: +1 (Positive) or -1 (Negative).
- **Strength**: 0.0 to 1.0 (Magnitude).
- **Confidence**: 0.0 to 1.0 (Certainty).
- **Type**: `affect`, `cognition`, `behavior_intent`...

### 3. Measurement Aggregation
The `services/measurement/measurement.ts` module aggregates raw `Evidence[]` into stable `ConstructMeasurement` objects.
- **Mean**: Weighted average of evidence strength.
- **Sigma**: Uncertainty measure.
    - **Invariance**: Sigma varies by source type (Text=0.3 > Choice=0.2 > Slider=0.1).
    - **Consistency**: Conflict in evidence inflates sigma (prevents overwriting).

### 4. Parameter Mapping & Governance
The `services/measurement/param_map.ts` module deterministically converts `ConstructMeasurement` into the frozen core's `EncodedSignal`.
- **Booster**: Cold start (n<3) allows faster updates.
- **Governor**: Established signals capped at 0.15 delta per step.
- **Saturation**: Signals dampen as they approach extremes.

## Validation & Quality

### Item Bank
`services/measurement/item_bank.ts` validates all LLM-generated questions against:
- **Clarity**: Length, double-barreled checks.
- **Construct Validity**: Ensures items match strictly defined taxonomies.

### Adaptive Information Gain
Sessions are no longer fixed length. The system evaluates `globalUncertainty`.
- **Exploration**: New users get up to 12 questions.
- **Maintenance**: Stable users stop early (~6 questions).

## Data Flow

1.  **Generation**: LLM generates valid `ItemSpec` (ItemBank checked).
2.  **Interaction**: User responds.
3.  **Normalization**:
    - **Choice**: Exact match on option label -> use stored `Evidence`.
    - **Text**: LLM Strict Coding -> extracts `Evidence[]`.
4.  **Aggregation**: `Evidence[]` -> `ConstructMeasurement` (Mean/Sigma, Conflict check).
5.  **Mapping**: `ConstructMeasurement` -> `EncodedSignal` (Core Parameters + Governance).
5.  **Inference**: Signals update the user's psychological state.

## Verification

Run the verification script to test the layer isolated from the UI:
```bash
npx tsx scripts/verify_measurement_layer.ts
```

## Cold Start Strategy
The session planner ensures coverage of at least 5 distinct constructs per session to rapidly build a baseline across the profile.
